\chapter{Conclusion}

FastClick and \Ac{vpp} are both fast software routers which vectorize
packets during processing and are close to each other performance
wise. MoonRoute on the other hand has a significant performance
advantage over both of them, being 20-30\% faster at routing.

While the performance of \Ac{vpp} v18.10 starts dropping at around 20
\Ac{fib} entries, \Ac{vpp} v16.09 can hold its highest performance
with up to 200 \Ac{ip4} \Ac{fib} entries. 

Reaching the maximum number of entries, \Ac{vpp}'s throughput nearly
halves with \Ac{vpp} v18.10 only supporting up to around 287,000
\Ac{ip4} \Ac{fib} entries. For this number of routing table entries it
is remarkably slower than FastClick with $2^{20}$ entries, even though
it is slightly faster with little table entries.

The best advantage of \Ac{vpp} over its competitors is its feature
richness. Its during runtime configurable packet processing graph
offers for example different tunneling protocols. Settings allow to
move the main thread to a dedicated CPU core which in turn allows live
inserts of 255k routing table entries with a temporary throughput
impact of less than a percent.

Although \Ac{vpp} performs badly with very big routing tables, its
modularity in combination with the rich options to connect it to
virtual machines, containers or local high performance applications,
make it a well choice for building virtual networks for highly
virtualized environments or implementation of \Ac{vnf}.

Next research steps could include more specific benchmarks regarding
behavior on receiving control packets or \Ac{ip6} specific
benchmarking methodology like RFC 5180 \cite{rfc5180}. Furthermore the
performance change over different \Ac{vpp} versions can be analyzed
closer by testing a version between 16.09 and 18.10 and the latest
v19.01 which was just released during the creation of this paper.
Especially the code changes leading to the performance differences and
how for example FastClick achieves its high performance with many
routes is of interest.

% TODO: this has to sound better

% more next steps: 
% - compare more vpp versions v19.01!
% - code based comparison of lookup table: v16.09, v18.10, fastclick
% - Understand where latency is introduced. model/plain why latency
%   per load graph looks like it does (read the relevant code)
% - try to elaborate a better upper bound throughput model as in: 
%   "Performance Exploration of Software-based Packet Processing Systems"
% 	- test with different cpus
% - test in virtualized scenarios
%   - take a look at open daylight / open flow / open stack to find out 
%     if there are good solutions to the terrible configuration problem 
% - test "smart" numa memory alignment
% - warmup time: somebody mentioned, that dpdk gets slower (less average throughput), 
%   when there is too little time between two busy polls
% - more interesting l2 histograms?